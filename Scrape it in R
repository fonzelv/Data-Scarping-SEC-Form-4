install.packages('rvest')
install.packages('xlsx')
install.packages('writexl')
install.packages("xml2")
#Loading the rvest package
library('xml2')
library('rvest')
library('tidyverse')  


tabella = data.frame()

#Setting up the URL - it looks for the first 1000 results in page 1
#Wiki_tickers is just a CSV with all the tickers you need to scrape, in my case it was the S&P500 list
for (tk in Wiki_tickers)
{link = paste0("http://openinsider.com/screener?s=", tk, "&o=&pl=&ph=&ll=&lh=&fd=0&fdr=&td=0&tdr=&fdlyl=&fdlyh=&daysago=&xp=1&xs=1&vl=&vh=&ocl=&och=&sic1=-1&sicl=100&sich=9999&grp=0&nfl=&nfh=&nil=&nih=&nol=&noh=&v2l=&v2h=&oc2l=&oc2h=&sortcol=0&cnt=900&page=1")}
  
for (i in link)
{page <- read_html(i)


  name =  page %>% 
         html_node('table.tinytable') %>%
         html_table(header=NA)
  
  tabella = rbind(tabella, name)}

  print(paste("page:", tk))  

write.csv(tabella,"INSERT FOLDER PATH")
